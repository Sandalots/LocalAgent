# ğŸ”§ Bug Fixes Applied

## Issues Found & Fixed:

### 1. âœ… **Dependencies Parsing Bug**
**Problem**: Comments in requirements.txt breaking pip install
```
faiss-cpu>=1.7.4  # or faiss-gpu for GPU support
```

**Fix**: Updated `_extract_dependencies()` to properly strip inline comments

### 2. âœ… **Entry Points Detection Bug**  
**Problem**: Found 113 entry points (including venv/site-packages files)

**Fix**: 
- Only search root directory (not recursive)
- Filter out venv, site-packages, hidden directories
- Use glob patterns: `main*.py`, `train*.py`, `run*.py`

### 3. âœ… **README-Based Execution**
**Added**: Parse README for python commands and prioritize them
- Looks for: `python3 main_local_all_new.py`
- Extracts arguments (like `--oracle`)
- Runs README scripts before generic entry points

### 4. âœ… **LLM Extraction Improvements**
**Problem**: Methodology and experiments returned empty (0 chars)

**Fix**:
- Better prompting for JSON extraction
- Added fallback regex-based extraction
- More explicit instructions to LLM

## ğŸ§ª Test Again

```bash
source .venv/bin/activate
python run.py
```

### Expected Behavior:
1. âœ… Find `main_local_all_new.py` as entry point
2. âœ… Parse dependencies correctly (no comments)
3. âœ… Extract paper sections with LLM
4. âœ… Run the correct experiment script from README

## ğŸ“Š What Should Happen Now:

```
âœ“ Found paper: 300_Decontextualization_Everyw.pdf
âœ“ Found code directory: ...
âœ“ Ollama is running
âœ“ Extracted abstract (XXX chars)
âœ“ Extracted methodology (XXX chars)  â† Should have content now
âœ“ Extracted experiments (XXX chars)  â† Should have content now
âœ“ Analyzed codebase (language: python)
âœ“ Found 1 potential entry points        â† Should be 1, not 113!
âœ“ Found 29 dependencies
Setting up experiment environment...
âœ“ Dependencies installed successfully   â† Should work now!
Found priority script from README: main_local_all_new.py
Running priority script: main_local_all_new.py
```

Try it now! ğŸš€
